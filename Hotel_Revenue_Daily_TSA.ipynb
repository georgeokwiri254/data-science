{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel Revenue Time Series Analysis - EDA & Preprocessing\n",
    "## Multi-Year Forecasting for 2025 Annual Close\n",
    "\n",
    "**Project Goal:** Predict hotel revenue metrics (RevPar, ADR, Revenue) for September - December 2025 using historical data from 2022-2025.\n",
    "\n",
    "**Current Date:** August 29, 2025\n",
    "\n",
    "**Data Splits:**\n",
    "- Training: 2022-01-01 to 2025-05-31\n",
    "- Validation: 2025-06-01 to 2025-08-29 (actuals for validation)\n",
    "- Test/Forecast: 2025-09-01 to 2025-12-31 (future forecast)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading\n",
    "\n",
    "### 1.1 Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistical libraries for time series\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key constants\n",
    "CURRENT_DATE = '2025-08-29'\n",
    "TARGET_VARIABLES = ['RevPar', 'ADR', 'Revenue', 'Occupancy_Pct']\n",
    "\n",
    "# Data split dates\n",
    "TRAIN_END = '2025-05-31'\n",
    "VALIDATION_START = '2025-06-01'\n",
    "VALIDATION_END = '2025-08-29'\n",
    "FORECAST_START = '2025-09-01'\n",
    "FORECAST_END = '2025-12-31'\n",
    "\n",
    "# Color palette for visualizations\n",
    "COLORS = sns.color_palette('husl', 8)\n",
    "\n",
    "print(f\"Configuration set:\")\n",
    "print(f\"  - Current Date: {CURRENT_DATE}\")\n",
    "print(f\"  - Training Period: 2022-01-01 to {TRAIN_END}\")\n",
    "print(f\"  - Validation Period: {VALIDATION_START} to {VALIDATION_END}\")\n",
    "print(f\"  - Forecast Period: {FORECAST_START} to {FORECAST_END}\")\n",
    "print(f\"  - Target Variables: {TARGET_VARIABLES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Ingestion (Google Colab File Upload)\n",
    "\n",
    "**Instructions:** Upload your `combined_occupancy_chronological.csv` file when prompted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab file upload\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload your combined_occupancy_chronological.csv file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "filename = list(uploaded.keys())[0]\n",
    "print(f\"\\nFile '{filename}' uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Convert Date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 2.1 Initial Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Number of records: {len(df)}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names:\\n{list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and memory usage\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TYPES AND MEMORY\")\n",
    "print(\"=\"*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last records\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIRST 5 RECORDS\")\n",
    "print(\"=\"*80)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LAST 5 RECORDS\")\n",
    "print(\"=\"*80)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\"*80)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing Count': missing.values,\n",
    "    'Percentage': missing_pct.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DUPLICATE CHECK\")\n",
    "print(\"=\"*80)\n",
    "duplicates = df.duplicated(subset='Date').sum()\n",
    "print(f\"Number of duplicate dates: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nDuplicate dates:\")\n",
    "    display(df[df.duplicated(subset='Date', keep=False)].sort_values('Date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all target variables over time\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12))\n",
    "\n",
    "for idx, var in enumerate(TARGET_VARIABLES):\n",
    "    axes[idx].plot(df['Date'], df[var], linewidth=1, color=COLORS[idx])\n",
    "    axes[idx].set_title(f'{var} Over Time (2022-2025)', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date', fontsize=11)\n",
    "    axes[idx].set_ylabel(var, fontsize=11)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical lines for data splits\n",
    "    axes[idx].axvline(x=pd.to_datetime(TRAIN_END), color='blue', linestyle='--', \n",
    "                      linewidth=1.5, label='Train End', alpha=0.7)\n",
    "    axes[idx].axvline(x=pd.to_datetime(VALIDATION_END), color='red', linestyle='--', \n",
    "                      linewidth=1.5, label='Current Date', alpha=0.7)\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots by Day of Week\n",
    "df['DayOfWeek_Name'] = df['Date'].dt.day_name()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, var in enumerate(TARGET_VARIABLES):\n",
    "    sns.boxplot(data=df[df['Date'] <= CURRENT_DATE], x='DayOfWeek_Name', y=var, \n",
    "                order=day_order, palette='Set2', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{var} Distribution by Day of Week', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Day of Week', fontsize=11)\n",
    "    axes[idx].set_ylabel(var, fontsize=11)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots by Month\n",
    "df['Month'] = df['Date'].dt.month\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, var in enumerate(TARGET_VARIABLES):\n",
    "    sns.boxplot(data=df[df['Date'] <= CURRENT_DATE], x='Month', y=var, \n",
    "                palette='viridis', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{var} Distribution by Month', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Month', fontsize=11)\n",
    "    axes[idx].set_ylabel(var, fontsize=11)\n",
    "    axes[idx].set_xticklabels(month_names)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose RevPar time series (only training data)\n",
    "train_eda = df[df['Date'] <= TRAIN_END].copy().set_index('Date')\n",
    "\n",
    "decomposition = seasonal_decompose(train_eda['RevPar'], model='additive', period=365)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12))\n",
    "\n",
    "decomposition.observed.plot(ax=axes[0], color='blue')\n",
    "axes[0].set_ylabel('Observed', fontsize=11)\n",
    "axes[0].set_title('Time Series Decomposition - RevPar (Training Data)', fontsize=14, fontweight='bold')\n",
    "\n",
    "decomposition.trend.plot(ax=axes[1], color='green')\n",
    "axes[1].set_ylabel('Trend', fontsize=11)\n",
    "\n",
    "decomposition.seasonal.plot(ax=axes[2], color='orange')\n",
    "axes[2].set_ylabel('Seasonal', fontsize=11)\n",
    "\n",
    "decomposition.resid.plot(ax=axes[3], color='red')\n",
    "axes[3].set_ylabel('Residual', fontsize=11)\n",
    "axes[3].set_xlabel('Date', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF for RevPar\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "plot_acf(train_eda['RevPar'].dropna(), lags=60, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF) - RevPar', fontsize=14, fontweight='bold')\n",
    "\n",
    "plot_pacf(train_eda['RevPar'].dropna(), lags=60, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF) - RevPar', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Stationarity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, name=''):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"\\nAugmented Dickey-Fuller Test - {name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ADF Statistic: {result[0]:.6f}\")\n",
    "    print(f\"p-value: {result[1]:.6f}\")\n",
    "    print(f\"Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"\\nResult: STATIONARY (p-value = {result[1]:.6f})\")\n",
    "    else:\n",
    "        print(f\"\\nResult: NON-STATIONARY (p-value = {result[1]:.6f})\")\n",
    "\n",
    "for var in TARGET_VARIABLES:\n",
    "    adf_test(train_eda[var], name=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Feature Engineering and Preprocessing\n",
    "\n",
    "Transform raw time series data into ML-ready features.\n",
    "\n",
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean copy\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Handle missing values using interpolation\n",
    "numeric_cols = ['Rm Sold', 'Revenue', 'ADR', 'RevPar', 'Occupancy_Pct']\n",
    "missing_before = df_clean[numeric_cols].isnull().sum().sum()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        df_clean[col] = df_clean[col].interpolate(method='linear')\n",
    "\n",
    "missing_after = df_clean[numeric_cols].isnull().sum().sum()\n",
    "print(f\"Missing values before: {missing_before}\")\n",
    "print(f\"Missing values after: {missing_after}\")\n",
    "print(\"\\n✓ Data cleaning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Temporal Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEMPORAL FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create temporal features\n",
    "df_clean['Year'] = df_clean['Date'].dt.year\n",
    "df_clean['Day_of_Week'] = df_clean['Date'].dt.dayofweek\n",
    "df_clean['Day_of_Year'] = df_clean['Date'].dt.dayofyear\n",
    "df_clean['Is_Weekend'] = ((df_clean['Date'].dt.dayofweek == 5) | \n",
    "                          (df_clean['Date'].dt.dayofweek == 6)).astype(int)\n",
    "df_clean['Quarter'] = df_clean['Date'].dt.quarter\n",
    "df_clean['Week_of_Year'] = df_clean['Date'].dt.isocalendar().week\n",
    "\n",
    "print(\"✓ Created 6 temporal features:\")\n",
    "print(\"  - Year, Month, Day_of_Week, Day_of_Year\")\n",
    "print(\"  - Is_Weekend, Quarter, Week_of_Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"LAGGED FEATURES\")\nprint(\"=\"*80)\n\nlag_features = ['RevPar', 'ADR', 'Occupancy_Pct', 'Revenue']\n# IMPROVED: Only use 1-day lag to reduce overfitting\n# 1-day lag provides immediate context from previous day\nlag_periods = [1]\n\nfor feature in lag_features:\n    for lag in lag_periods:\n        df_clean[f'{feature}_lag_{lag}'] = df_clean[feature].shift(lag)\n\nprint(f\"✓ Created {len(lag_features) * len(lag_periods)} lagged features\")\nprint(f\"  - Variables: {lag_features}\")\nprint(f\"  - Lags: {lag_periods} day (1-day only)\")\nprint(f\"  - Note: Using only 1-day lag for minimal complexity\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Moving Averages and Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"ROLLING STATISTICS\")\nprint(\"=\"*80)\n\n# IMPROVED: Remove MA/Rolling features for XGBoost to reduce multicollinearity\n# Tree-based models like XGBoost automatically capture these patterns\n# Keep these features commented out in case you use LSTM or SARIMA\n\nprint(\"✓ Skipping rolling features (MA, Std Dev) for XGBoost\")\nprint(\"  - Reason: XGBoost captures these patterns automatically\")\nprint(\"  - Reduces multicollinearity with lag features\")\nprint(\"  - If using LSTM/SARIMA, uncomment the code below:\")\nprint()\n\n# Uncomment below if using LSTM or SARIMA\n\"\"\"\nwindows = [7, 14, 30]\n\nfor feature in lag_features:\n    for window in windows:\n        df_clean[f'{feature}_ma_{window}'] = df_clean[feature].rolling(\n            window=window, min_periods=1).mean()\n        df_clean[f'{feature}_std_{window}'] = df_clean[feature].rolling(\n            window=window, min_periods=1).std()\n\nprint(f\"✓ Created {len(lag_features) * len(windows) * 2} rolling features\")\nprint(f\"  - Statistics: Mean, Std Dev\")\nprint(f\"  - Windows: {windows} days\")\n\"\"\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ONE-HOT ENCODING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# One-Hot Encode Day of Week (if DOW column exists)\n",
    "if 'DOW' in df_clean.columns:\n",
    "    dow_dummies = pd.get_dummies(df_clean['DOW'], prefix='DOW')\n",
    "    df_clean = pd.concat([df_clean, dow_dummies], axis=1)\n",
    "    print(f\"✓ Created {len(dow_dummies.columns)} DOW dummy variables\")\n",
    "else:\n",
    "    # Create from DayOfWeek_Name if it exists\n",
    "    dow_dummies = pd.get_dummies(df_clean['DayOfWeek_Name'], prefix='DOW')\n",
    "    df_clean = pd.concat([df_clean, dow_dummies], axis=1)\n",
    "    print(f\"✓ Created {len(dow_dummies.columns)} DOW dummy variables\")\n",
    "\n",
    "# One-Hot Encode Month\n",
    "month_dummies = pd.get_dummies(df_clean['Month'], prefix='Month')\n",
    "df_clean = pd.concat([df_clean, month_dummies], axis=1)\n",
    "print(f\"✓ Created {len(month_dummies.columns)} Month dummy variables\")\n",
    "\n",
    "# Convert boolean to int\n",
    "bool_cols = [col for col in df_clean.columns if df_clean[col].dtype == 'bool']\n",
    "for col in bool_cols:\n",
    "    df_clean[col] = df_clean[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Chronological Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"DATA SPLITTING\")\nprint(\"=\"*80)\n\n# FILTER: Use only post-COVID data for more accurate forecasting\nprint(\"\\n⚠️  Filtering to post-COVID data (2022+) for more relevant patterns\")\ndf_clean = df_clean[df_clean['Date'] >= '2022-01-01'].copy()\nprint(f\"Filtered dataset: {len(df_clean)} records from {df_clean['Date'].min()} to {df_clean['Date'].max()}\")\n\n# Create splits\ntrain_data = df_clean[df_clean['Date'] <= TRAIN_END].copy()\nvalidation_data = df_clean[(df_clean['Date'] >= VALIDATION_START) & \n                           (df_clean['Date'] <= VALIDATION_END)].copy()\ntest_data = df_clean[(df_clean['Date'] >= FORECAST_START) & \n                     (df_clean['Date'] <= FORECAST_END)].copy()\n\nprint(f\"\\nTraining Set:\")\nprint(f\"  Period: {train_data['Date'].min()} to {train_data['Date'].max()}\")\nprint(f\"  Records: {len(train_data)}\")\n\nprint(f\"\\nValidation Set:\")\nprint(f\"  Period: {validation_data['Date'].min()} to {validation_data['Date'].max()}\")\nprint(f\"  Records: {len(validation_data)}\")\n\nprint(f\"\\nTest/Forecast Set:\")\nprint(f\"  Period: {test_data['Date'].min()} to {test_data['Date'].max()}\")\nprint(f\"  Records: {len(test_data)}\")\n\nprint(f\"\\nTotal: {len(df_clean)} records\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE SCALING (STANDARDIZATION)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Columns NOT to scale\n",
    "cols_not_to_scale = ['Date', 'Year', 'Month', 'Day_of_Week', 'Day_of_Year', \n",
    "                     'Is_Weekend', 'Quarter', 'Week_of_Year', 'DayOfWeek_Name']\n",
    "cols_not_to_scale += [col for col in df_clean.columns if col.startswith('DOW_') or col.startswith('Month_')]\n",
    "\n",
    "# Get numeric columns to scale\n",
    "numeric_cols_all = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cols_to_scale = [col for col in numeric_cols_all if col not in cols_not_to_scale]\n",
    "\n",
    "print(f\"Columns NOT scaled: {len(cols_not_to_scale)}\")\n",
    "print(f\"Columns TO scale: {len(cols_to_scale)}\")\n",
    "\n",
    "# Fit scaler ONLY on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data[cols_to_scale])\n",
    "\n",
    "# Transform all datasets\n",
    "train_data[cols_to_scale] = scaler.transform(train_data[cols_to_scale])\n",
    "validation_data[cols_to_scale] = scaler.transform(validation_data[cols_to_scale])\n",
    "test_data[cols_to_scale] = scaler.transform(test_data[cols_to_scale])\n",
    "\n",
    "print(\"\\n✓ StandardScaler fitted on training data\")\n",
    "print(\"✓ Applied to train, validation, and test sets\")",
    "\n",
    "# Note: scaler and cols_to_scale are saved for inverse transform later\n",
    "# They will be used to convert predictions back to original scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Create ML-Ready Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"ML-READY DATASET\")\nprint(\"=\"*80)\n\n# Combine all data\nml_ready_data = pd.concat([train_data, validation_data, test_data], ignore_index=True)\n\n# Add dataset identifier\nml_ready_data['Dataset'] = 'Train'\nml_ready_data.loc[ml_ready_data['Date'] >= VALIDATION_START, 'Dataset'] = 'Validation'\nml_ready_data.loc[ml_ready_data['Date'] >= FORECAST_START, 'Dataset'] = 'Test'\n\n# Drop redundant columns before export\nredundant_cols = ['DOW', 'DayOfWeek_Name', 'Rm Sold']\ncols_to_drop = [col for col in redundant_cols if col in ml_ready_data.columns]\nif cols_to_drop:\n    ml_ready_data = ml_ready_data.drop(columns=cols_to_drop)\n    print(f\"\\n✓ Removed {len(cols_to_drop)} redundant columns: {cols_to_drop}\")\n\nprint(f\"\\nTotal records: {len(ml_ready_data)}\")\nprint(f\"Total features: {len(ml_ready_data.columns)}\")\nprint(f\"Date range: {ml_ready_data['Date'].min()} to {ml_ready_data['Date'].max()}\")\n\nprint(f\"\\nDataset Distribution:\")\nprint(ml_ready_data['Dataset'].value_counts().sort_index())\n\nprint(\"\\nSample of ML-Ready Data:\")\n# FIXED: Updated column references to match actual features created\ndisplay(ml_ready_data[['Date', 'RevPar', 'RevPar_lag_1',\n                       'Is_Weekend', 'Dataset']].head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Export ML-Ready Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_filename = 'combined_occupancy_ml_ready.csv'\n",
    "ml_ready_data.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPORT COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ ML-ready data saved: {output_filename}\")\n",
    "print(f\"✓ Ready for model training and forecasting\")\n",
    "\n",
    "# Download\n",
    "files.download(output_filename)\n",
    "print(f\"\\n✓ File downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Preprocessing Summary\n\n**Completed Steps:**\n1. ✓ Data cleaning and missing value imputation\n2. ✓ Temporal features (Day of Week, Month, Quarter, etc.)\n3. ✓ Lagged variables (1-day lag only)\n4. ✓ Moving averages: REMOVED (not needed for XGBoost)\n5. ✓ One-hot encoding (DOW, Month)\n6. ✓ Chronological data splitting (Train/Validation/Test)\n7. ✓ Feature scaling (StandardScaler fitted on training only)\n8. ✓ Export ML-ready dataset\n\n**Next Steps:**\n- Model training (XGBoost, SARIMA, LSTM)\n- Model evaluation on validation set\n- Final forecast: September - December 2025"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Model Training and Selection\n",
    "\n",
    "Train top-ranked models using the prepared training data.\n",
    "\n",
    "### 4.0 Load Preprocessed ML-Ready Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have ml_ready_data from Section 3, skip this cell\n",
    "# Otherwise, upload the preprocessed file\n",
    "\n",
    "print(\"Upload combined_occupancy_ml_ready.csv if not already in memory:\")\n",
    "try:\n",
    "    # Check if ml_ready_data exists\n",
    "    print(f\"ML-ready data already loaded: {ml_ready_data.shape}\")\n",
    "except NameError:\n",
    "    # Upload and load the preprocessed file\n",
    "    uploaded_ml = files.upload()\n",
    "    ml_filename = list(uploaded_ml.keys())[0]\n",
    "    ml_ready_data = pd.read_csv(ml_filename)\n",
    "    ml_ready_data['Date'] = pd.to_datetime(ml_ready_data['Date'])\n",
    "    print(f\"ML-ready data loaded: {ml_ready_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for modeling\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING DATA FOR MODELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Split by Dataset identifier\n",
    "train_df = ml_ready_data[ml_ready_data['Dataset'] == 'Train'].copy()\n",
    "val_df = ml_ready_data[ml_ready_data['Dataset'] == 'Validation'].copy()\n",
    "test_df = ml_ready_data[ml_ready_data['Dataset'] == 'Test'].copy()\n",
    "\n",
    "print(f\"\\nTraining Set: {len(train_df)} records\")\n",
    "print(f\"Validation Set: {len(val_df)} records\")\n",
    "print(f\"Test Set: {len(test_df)} records\")\n",
    "\n",
    "# Define feature columns (exclude non-features)\n",
    "# Define feature columns (exclude non-features)\n",
    "exclude_cols = ['Date', 'Dataset', 'DayOfWeek_Name', 'DOW', 'Rm Sold'] + TARGET_VARIABLES\n",
    "feature_cols = [col for col in ml_ready_data.columns if col not in exclude_cols]\n",
    "\n",
    "# Remove any columns with NaN (from lagging)\n",
    "train_df_clean = train_df.dropna()\n",
    "val_df_clean = val_df.dropna()\n",
    "\n",
    "print(f\"\\nFeature columns: {len(feature_cols)}\")\n",
    "print(f\"Training set after removing NaN: {len(train_df_clean)} records\")\n",
    "print(f\"Validation set after removing NaN: {len(val_df_clean)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 4.0.1 Important Note: Data Scaling Strategy\n\n**Different models require different data scales:**\n\n1. **SARIMA (Statistical Model)**\n   - Trains on **ORIGINAL (unscaled)** data\n   - Statistical models expect data in its natural scale\n   - Predictions are directly in AED (currency units)\n   - Better performance when working with actual values\n\n2. **XGBoost (Tree-based Model)**\n   - Trains on **SCALED** data\n   - Benefits from standardization for regularization\n   - Predictions need inverse transformation back to AED\n\n3. **LSTM (Neural Network)**\n   - Trains on **SCALED** data  \n   - Neural networks require normalized inputs for optimization\n   - Predictions need inverse transformation back to AED\n\n**Why this matters:**\n- SARIMA was performing poorly when trained on scaled data\n- Each model type has different requirements for optimal performance\n- We maintain separate datasets to ensure each model gets the appropriate scale",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline Model: SARIMA\n",
    "\n",
    "Establish a performance benchmark using SARIMA (Seasonal ARIMA)."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Import SARIMA libraries\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nprint(\"=\"*80)\nprint(\"BASELINE MODEL: SARIMA (ON ORIGINAL SCALE)\")\nprint(\"=\"*80)\n\n# IMPORTANT: SARIMA trains on ORIGINAL (unscaled) data\n# Statistical models like SARIMA perform better on original scale\n# XGBoost and LSTM will use scaled data\n\n# Prepare data for SARIMA (RevPar only, simple univariate) - ORIGINAL SCALE\ntrain_sarima = train_df_clean_original.set_index('Date')['RevPar']\nval_sarima = val_df_clean_original.set_index('Date')['RevPar']\n\nprint(f\"\\nSARIMA Training Data (Original Scale):\")\nprint(f\"  Records: {len(train_sarima)}\")\nprint(f\"  RevPar range: AED {train_sarima.min():.2f} - {train_sarima.max():.2f}\")\nprint(f\"  Mean: AED {train_sarima.mean():.2f}\")\n\n# Train SARIMA model\n# Order (p,d,q) and seasonal order (P,D,Q,s)\n# Using monthly seasonality (s=30) - hotel bookings have monthly patterns\nsarima_model = SARIMAX(train_sarima,\n                       order=(2, 1, 2),  # (p,d,q) - increased complexity\n                       seasonal_order=(1, 1, 1, 30),  # (P,D,Q,s) - MONTHLY seasonality\n                       enforce_stationarity=False,\n                       enforce_invertibility=False)\n\nprint(\"\\nTraining SARIMA model on original scale...\")\nsarima_fit = sarima_model.fit(disp=False, maxiter=200)\nprint(\"✓ SARIMA model trained on ORIGINAL (unscaled) data\")\n\n# Predict on validation set\nsarima_val_pred = sarima_fit.forecast(steps=len(val_sarima))\n\n# Calculate metrics (already in original scale)\nsarima_rmse = np.sqrt(mean_squared_error(val_sarima, sarima_val_pred))\nsarima_mae = mean_absolute_error(val_sarima, sarima_val_pred)\nsarima_r2 = r2_score(val_sarima, sarima_val_pred)\nsarima_mape = np.mean(np.abs((val_sarima - sarima_val_pred) / val_sarima)) * 100\n\nprint(f\"\\nSARIMA Validation Performance (Original Scale):\")\nprint(f\"  RMSE: AED {sarima_rmse:.2f}\")\nprint(f\"  MAE: AED {sarima_mae:.2f}\")\nprint(f\"  R²: {sarima_r2:.4f}\")\nprint(f\"  MAPE: {sarima_mape:.2f}%\")\n\nprint(f\"\\n✓ SARIMA predictions are in ORIGINAL SCALE (AED)\")\nprint(f\"  Prediction range: AED {sarima_val_pred.min():.2f} - {sarima_val_pred.max():.2f}\")\n\n# Store results\nresults = {\n    'SARIMA': {'RMSE': sarima_rmse, 'MAE': sarima_mae, 'R2': sarima_r2, 'MAPE': sarima_mape}\n}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SARIMA libraries\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BASELINE MODEL: SARIMA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for SARIMA (RevPar only, simple univariate)\n",
    "train_sarima = train_df_clean.set_index('Date')['RevPar']\n",
    "val_sarima = val_df_clean.set_index('Date')['RevPar']\n",
    "\n",
    "# Train SARIMA model\n",
    "# Order (p,d,q) and seasonal order (P,D,Q,s)\n",
    "# Using weekly seasonality (s=7)\n",
    "sarima_model = SARIMAX(train_sarima, \n",
    "                       order=(1, 1, 1),  # (p,d,q)\n",
    "                       seasonal_order=(1, 1, 1, 7),  # (P,D,Q,s) - weekly\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "\n",
    "print(\"\\nTraining SARIMA model...\")\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "print(\"✓ SARIMA model trained\")\n",
    "\n",
    "# Predict on validation set\n",
    "sarima_val_pred = sarima_fit.forecast(steps=len(val_sarima))\n",
    "\n",
    "# Calculate metrics\n",
    "sarima_rmse = np.sqrt(mean_squared_error(val_sarima, sarima_val_pred))\n",
    "sarima_mae = mean_absolute_error(val_sarima, sarima_val_pred)\n",
    "sarima_r2 = r2_score(val_sarima, sarima_val_pred)\n",
    "\n",
    "print(f\"\\nSARIMA Validation Performance:\")\n",
    "print(f\"  RMSE: {sarima_rmse:.2f}\")\n",
    "print(f\"  MAE: {sarima_mae:.2f}\")\n",
    "print(f\"  R²: {sarima_r2:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results = {\n",
    "    'SARIMA': {'RMSE': sarima_rmse, 'MAE': sarima_mae, 'R2': sarima_r2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Advanced Model: XGBoost Regressor\n",
    "\n",
    "Train XGBoost for multi-output regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import XGBoost\nimport xgboost as xgb\nfrom sklearn.multioutput import MultiOutputRegressor\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ADVANCED MODEL: XGBOOST REGRESSOR\")\nprint(\"=\"*80)\n\n# Prepare data\nX_train = train_df_clean[feature_cols]\ny_train = train_df_clean[TARGET_VARIABLES]\n\nX_val = val_df_clean[feature_cols]\ny_val = val_df_clean[TARGET_VARIABLES]\n\nprint(f\"\\nTraining features shape: {X_train.shape}\")\nprint(f\"Training targets shape: {y_train.shape}\")\n\n# IMPROVED: Add regularization to prevent overfitting\n# Reduced max_depth, learning_rate, and colsample_bytree\n# Added L1/L2 regularization (reg_alpha, reg_lambda)\nxgb_model = xgb.XGBRegressor(\n    n_estimators=200,\n    max_depth=5,  # Reduced from 6\n    learning_rate=0.05,  # Reduced from 0.1\n    subsample=0.8,\n    colsample_bytree=0.7,  # Reduced from 0.8\n    reg_alpha=0.1,  # L1 regularization (NEW)\n    reg_lambda=1.0,  # L2 regularization (NEW)\n    min_child_weight=3,  # Prevents overfitting (NEW)\n    random_state=42,\n    n_jobs=-1\n)\n\n# Use MultiOutputRegressor for multiple targets\nmulti_xgb = MultiOutputRegressor(xgb_model)\n\nprint(\"\\nTraining XGBoost model with regularization...\")\nmulti_xgb.fit(X_train, y_train)\nprint(\"✓ XGBoost model trained\")\n\n# Predict on validation set\nxgb_val_pred = multi_xgb.predict(X_val)\n\n# FIXED: Inverse transform predictions and actuals to original scale\nxgb_val_pred_original = xgb_val_pred.copy()\ny_val_original = y_val.copy()\n\n# Inverse transform each target column\nfor idx_col, target in enumerate(TARGET_VARIABLES):\n    if target in cols_to_scale:\n        # Get the scaler index for this target\n        target_idx = cols_to_scale.index(target)\n        \n        # Inverse transform predictions\n        dummy_pred = np.zeros((len(xgb_val_pred), len(cols_to_scale)))\n        dummy_pred[:, target_idx] = xgb_val_pred[:, idx_col]\n        inv_transformed_pred = scaler.inverse_transform(dummy_pred)\n        xgb_val_pred_original[:, idx_col] = inv_transformed_pred[:, target_idx]\n        \n        # Inverse transform actuals\n        dummy_actual = np.zeros((len(y_val), len(cols_to_scale)))\n        dummy_actual[:, target_idx] = y_val.iloc[:, idx_col]\n        inv_transformed_actual = scaler.inverse_transform(dummy_actual)\n        y_val_original.iloc[:, idx_col] = inv_transformed_actual[:, target_idx]\n\n# Calculate metrics for each target (on scaled data for consistency)\nprint(f\"\\nXGBoost Validation Performance (Scaled Data):\")\nxgb_metrics = {}\nfor idx, target in enumerate(TARGET_VARIABLES):\n    rmse = np.sqrt(mean_squared_error(y_val.iloc[:, idx], xgb_val_pred[:, idx]))  # FIXED: Removed extra )\n    mae = mean_absolute_error(y_val.iloc[:, idx], xgb_val_pred[:, idx])  # FIXED: Removed extra )\n    r2 = r2_score(y_val.iloc[:, idx], xgb_val_pred[:, idx])\n    \n    xgb_metrics[target] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n    print(f\"\\n  {target}:\")\n    print(f\"    RMSE: {rmse:.2f}\")\n    print(f\"    MAE: {mae:.2f}\")\n    print(f\"    R²: {r2:.4f}\")\n\nresults['XGBoost'] = xgb_metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Validation Set: Actual vs Predicted Comparison\n",
    "\n",
    "Compare predictions against actual values (June-August 2025) in original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION SET: ACTUAL VS PREDICTED (ORIGINAL SCALE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Recalculate metrics on original scale\n",
    "print(f\"\\nXGBoost Validation Performance (Original Scale):\")\n",
    "xgb_metrics_original = {}\n",
    "for idx_col, target in enumerate(TARGET_VARIABLES):\n",
    "    actual = y_val_original.iloc[:, idx_col]\n",
    "    predicted = xgb_val_pred_original[:, idx_col]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    \n",
    "    # Calculate MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    \n",
    "    xgb_metrics_original[target] = {\n",
    "        'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  {target}:\")\n",
    "    print(f\"    RMSE: AED {rmse:,.2f}\" if 'Revenue' in target or 'ADR' in target or 'RevPar' in target else f\"    RMSE: {rmse:.2f}%\")\n",
    "    print(f\"    MAE: AED {mae:,.2f}\" if 'Revenue' in target or 'ADR' in target or 'RevPar' in target else f\"    MAE: {mae:.2f}%\")\n",
    "    print(f\"    R²: {r2:.4f}\")\n",
    "    print(f\"    MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Date': val_df_clean['Date'].values,\n",
    "})\n",
    "\n",
    "for idx_col, target in enumerate(TARGET_VARIABLES):\n",
    "    comparison_df[f'{target}_Actual'] = y_val_original.iloc[:, idx_col].values\n",
    "    comparison_df[f'{target}_Predicted'] = xgb_val_pred_original[:, idx_col]\n",
    "    comparison_df[f'{target}_Error'] = comparison_df[f'{target}_Actual'] - comparison_df[f'{target}_Predicted']\n",
    "    comparison_df[f'{target}_Error_Pct'] = (comparison_df[f'{target}_Error'] / comparison_df[f'{target}_Actual']) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION COMPARISON SAMPLE (First 10 days)\")\n",
    "print(\"=\"*80)\n",
    "display(comparison_df[['Date', 'RevPar_Actual', 'RevPar_Predicted', 'RevPar_Error', 'RevPar_Error_Pct']].head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION PERIOD SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for target in TARGET_VARIABLES:\n",
    "    actual_total = comparison_df[f'{target}_Actual'].sum()\n",
    "    predicted_total = comparison_df[f'{target}_Predicted'].sum()\n",
    "    diff = predicted_total - actual_total\n",
    "    diff_pct = (diff / actual_total) * 100\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    if 'Revenue' in target:\n",
    "        print(f\"  Actual Total: AED {actual_total:,.2f}\")\n",
    "        print(f\"  Predicted Total: AED {predicted_total:,.2f}\")\n",
    "        print(f\"  Difference: AED {diff:,.2f} ({diff_pct:+.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  Actual Average: {comparison_df[f'{target}_Actual'].mean():.2f}\")\n",
    "        print(f\"  Predicted Average: {comparison_df[f'{target}_Predicted'].mean():.2f}\")\n",
    "        print(f\"  Difference: {comparison_df[f'{target}_Predicted'].mean() - comparison_df[f'{target}_Actual'].mean():+.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Advanced Model: LSTM Neural Network\n",
    "\n",
    "Train LSTM for sequential time series prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import TensorFlow/Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ADVANCED MODEL: LSTM NEURAL NETWORK\")\nprint(\"=\"*80)\n\n# Prepare data for LSTM (reshape to 3D: samples, timesteps, features)\ndef create_sequences(X, y, timesteps=7):\n    Xs, ys = [], []\n    for i in range(len(X) - timesteps):\n        Xs.append(X.iloc[i:(i + timesteps)].values)\n        ys.append(y.iloc[i + timesteps].values)\n    return np.array(Xs), np.array(ys)\n\ntimesteps = 7  # Use 7 days of history\n\n# FIXED: Ensure all data is float32 for TensorFlow compatibility\nX_train_float32 = X_train.astype(np.float32)\ny_train_float32 = y_train.astype(np.float32)\nX_val_float32 = X_val.astype(np.float32)\ny_val_float32 = y_val.astype(np.float32)\n\nX_train_lstm, y_train_lstm = create_sequences(X_train_float32, y_train_float32, timesteps)\nX_val_lstm, y_val_lstm = create_sequences(X_val_float32, y_val_float32, timesteps)\n\nprint(f\"\\nLSTM Training data shape: {X_train_lstm.shape}\")\nprint(f\"\\nLSTM Validation data shape: {X_val_lstm.shape}\")\n\n# Build LSTM model - SIMPLIFIED to reduce overfitting\nlstm_model = Sequential([\n    LSTM(32, activation='tanh', return_sequences=False,  # REDUCED from 128\n         input_shape=(timesteps, X_train.shape[1])),\n    Dropout(0.3),  # INCREASED dropout from 0.2\n    Dense(16, activation='relu'),  # REDUCED from 32\n    Dense(len(TARGET_VARIABLES))  # Output layer for all targets\n])\n\n# Use lower learning rate to prevent overfitting\nlstm_model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n\nprint(\"\\nLSTM Model Architecture (Simplified):\")\nlstm_model.summary()\n\n# Early stopping callback\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train LSTM with reduced epochs and batch size\nprint(\"\\nTraining LSTM model with reduced complexity...\")\nhistory = lstm_model.fit(\n    X_train_lstm, y_train_lstm,\n    validation_data=(X_val_lstm, y_val_lstm),\n    epochs=50,  # REDUCED from 100\n    batch_size=16,  # REDUCED from 32\n    callbacks=[early_stop],\n    verbose=0\n)\nprint(\"✓ LSTM model trained\")\n\n# Predict on validation set\nlstm_val_pred = lstm_model.predict(X_val_lstm, verbose=0)\n\n# Calculate metrics\nprint(f\"\\nLSTM Validation Performance:\")\nlstm_metrics = {}\nfor idx, target in enumerate(TARGET_VARIABLES):\n    rmse = np.sqrt(mean_squared_error(y_val_lstm[:, idx], lstm_val_pred[:, idx]))\n    mae = mean_absolute_error(y_val_lstm[:, idx], lstm_val_pred[:, idx])\n    r2 = r2_score(y_val_lstm[:, idx], lstm_val_pred[:, idx])\n    \n    lstm_metrics[target] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n    print(f\"\\n  {target}:\")\n    print(f\"    RMSE: {rmse:.2f}\")\n    print(f\"    MAE: {mae:.2f}\")\n    print(f\"    R²: {r2:.4f}\")\n\nresults['LSTM'] = lstm_metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Training Loss Visualization (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LSTM training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('LSTM Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=11)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_title('LSTM Model MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1].set_ylabel('MAE', fontsize=11)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "print(\"=\"*80)\nprint(\"MODEL COMPARISON - VALIDATION SET\")\nprint(\"=\"*80)\n\n# IMPORTANT NOTE: \n# - SARIMA metrics are in ORIGINAL SCALE (AED)\n# - XGBoost and LSTM metrics are in SCALED units\n# For fair comparison, we compare them separately or convert to same scale\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SARIMA Performance (Original Scale - AED)\")\nprint(\"=\"*80)\nprint(f\"\\nRevPar Prediction:\")\nprint(f\"  RMSE: AED {results['SARIMA']['RMSE']:.2f}\")\nprint(f\"  MAE: AED {results['SARIMA']['MAE']:.2f}\")\nprint(f\"  R²: {results['SARIMA']['R2']:.4f}\")\nprint(f\"  MAPE: {results['SARIMA']['MAPE']:.2f}%\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"XGBoost Performance (Original Scale - from Section 4.2.1)\")\nprint(\"=\"*80)\n# Use the metrics calculated in original scale from cell 53\nfor target in TARGET_VARIABLES:\n    if target in xgb_metrics_original:\n        print(f\"\\n{target}:\")\n        metrics = xgb_metrics_original[target]\n        if 'Revenue' in target or 'ADR' in target or 'RevPar' in target:\n            print(f\"  RMSE: AED {metrics['RMSE']:,.2f}\")\n            print(f\"  MAE: AED {metrics['MAE']:,.2f}\")\n        else:\n            print(f\"  RMSE: {metrics['RMSE']:.2f}%\")\n            print(f\"  MAE: {metrics['MAE']:.2f}%\")\n        print(f\"  R²: {metrics['R2']:.4f}\")\n        print(f\"  MAPE: {metrics['MAPE']:.2f}%\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"LSTM Performance (Scaled Data)\")\nprint(\"=\"*80)\nprint(\"Note: LSTM metrics are in scaled units (not directly comparable to SARIMA)\")\nfor target in TARGET_VARIABLES:\n    print(f\"\\n{target}:\")\n    print(f\"  RMSE: {results['LSTM'][target]['RMSE']:.2f} (scaled)\")\n    print(f\"  MAE: {results['LSTM'][target]['MAE']:.2f} (scaled)\")\n    print(f\"  R²: {results['LSTM'][target]['R2']:.4f}\")\n\n# Create comparison visualization (RevPar only, original scale)\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUAL COMPARISON - RevPar (Original Scale)\")\nprint(\"=\"*80)\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# Compare SARIMA vs XGBoost (both in original scale)\nmodels_to_compare = ['SARIMA', 'XGBoost']\nmetrics_to_plot = ['RMSE', 'MAE', 'MAPE']\nmetric_values = {\n    'SARIMA': [\n        results['SARIMA']['RMSE'],\n        results['SARIMA']['MAE'],\n        results['SARIMA']['MAPE']\n    ],\n    'XGBoost': [\n        xgb_metrics_original['RevPar']['RMSE'],\n        xgb_metrics_original['RevPar']['MAE'],\n        xgb_metrics_original['RevPar']['MAPE']\n    ]\n}\n\nfor idx, metric in enumerate(metrics_to_plot):\n    values = [metric_values[model][idx] for model in models_to_compare]\n    axes[idx].bar(models_to_compare, values, color=['skyblue', 'orange'])\n    \n    if metric == 'MAPE':\n        axes[idx].set_title(f'{metric} Comparison - RevPar (%)', fontsize=14, fontweight='bold')\n        axes[idx].set_ylabel(f'{metric} (%)', fontsize=11)\n    else:\n        axes[idx].set_title(f'{metric} Comparison - RevPar (AED)', fontsize=14, fontweight='bold')\n        axes[idx].set_ylabel(f'{metric} (AED)', fontsize=11)\n    \n    axes[idx].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for i, v in enumerate(values):\n        axes[idx].text(i, v, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL SELECTION SUMMARY\")\nprint(\"=\"*80)\nprint(\"\\nKey Findings:\")\nprint(f\"  - SARIMA trained on ORIGINAL scale performs better for statistical modeling\")\nprint(f\"  - XGBoost trained on SCALED data benefits from regularization\")\nprint(f\"  - LSTM trained on SCALED data for neural network optimization\")\nprint(f\"\\nRecommendation: Use XGBoost for final forecast (multi-target, best R²)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON - VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "\n",
    "# SARIMA (RevPar only)\n",
    "comparison_data.append({\n",
    "    'Model': 'SARIMA',\n",
    "    'Target': 'RevPar',\n",
    "    'RMSE': results['SARIMA']['RMSE'],\n",
    "    'MAE': results['SARIMA']['MAE'],\n",
    "    'R²': results['SARIMA']['R2']\n",
    "})\n",
    "\n",
    "# XGBoost\n",
    "for target in TARGET_VARIABLES:\n",
    "    comparison_data.append({\n",
    "        'Model': 'XGBoost',\n",
    "        'Target': target,\n",
    "        'RMSE': results['XGBoost'][target]['RMSE'],\n",
    "        'MAE': results['XGBoost'][target]['MAE'],\n",
    "        'R²': results['XGBoost'][target]['R2']\n",
    "    })\n",
    "\n",
    "# LSTM\n",
    "for target in TARGET_VARIABLES:\n",
    "    comparison_data.append({\n",
    "        'Model': 'LSTM',\n",
    "        'Target': target,\n",
    "        'RMSE': results['LSTM'][target]['RMSE'],\n",
    "        'MAE': results['LSTM'][target]['MAE'],\n",
    "        'R²': results['LSTM'][target]['R2']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R²']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    revpar_data = comparison_df[comparison_df['Target'] == 'RevPar']\n",
    "    axes[idx].bar(revpar_data['Model'], revpar_data[metric], \n",
    "                  color=['skyblue', 'orange', 'green'])\n",
    "    axes[idx].set_title(f'{metric} Comparison (RevPar)', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_ylabel(metric, fontsize=11)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Final Model Training (All Historical Data)\n",
    "\n",
    "Retrain the best model using all available data up to August 29, 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"FINAL MODEL TRAINING (TRAIN + VALIDATION)\")\nprint(\"=\"*80)\n\n# Combine train and validation for final training\nfinal_train_df = pd.concat([train_df_clean, val_df_clean]).reset_index(drop=True)\n\nX_final = final_train_df[feature_cols]\ny_final = final_train_df[TARGET_VARIABLES]\n\nprint(f\"\\nFinal training set: {X_final.shape[0]} records\")\nprint(f\"Date range: {final_train_df['Date'].min()} to {final_train_df['Date'].max()}\")\n\n# Retrain XGBoost with improved regularization parameters\nprint(\"\\nRetraining XGBoost on all historical data with regularization...\")\nfinal_xgb = MultiOutputRegressor(xgb.XGBRegressor(\n    n_estimators=200,\n    max_depth=5,  # Reduced from 6\n    learning_rate=0.05,  # Reduced from 0.1\n    subsample=0.8,\n    colsample_bytree=0.7,  # Reduced from 0.8\n    reg_alpha=0.1,  # L1 regularization\n    reg_lambda=1.0,  # L2 regularization\n    min_child_weight=3,  # Prevents overfitting\n    random_state=42,\n    n_jobs=-1\n))\n\nfinal_xgb.fit(X_final, y_final)\nprint(\"✓ Final XGBoost model trained with regularization\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Forecasting the Future (Sept - Dec 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL FORECAST: SEPTEMBER - DECEMBER 2025\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare test data (handle NaN from lagging)\n",
    "# For forecasting, we need to handle missing lag values\n",
    "# Use forward fill or last known values\n",
    "test_df_forecast = test_df.copy()\n",
    "\n",
    "# Fill NaN with forward fill (use last known values)\n",
    "for col in feature_cols:\n",
    "    if test_df_forecast[col].isnull().any():\n",
    "        # Fill with the last value from validation set\n",
    "        last_val = val_df_clean[col].iloc[-1] if col in val_df_clean.columns else 0\n",
    "        test_df_forecast[col].fillna(last_val, inplace=True)\n",
    "\n",
    "X_test = test_df_forecast[feature_cols]\n",
    "\n",
    "print(f\"\\nTest set for forecasting: {X_test.shape[0]} records\")\n",
    "print(f\"Date range: {test_df_forecast['Date'].min()} to {test_df_forecast['Date'].max()}\")\n",
    "\n",
    "# Make predictions\n",
    "final_predictions = final_xgb.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions to original scale\n",
    "final_predictions_original = final_predictions.copy()\n",
    "for idx_col, target in enumerate(TARGET_VARIABLES):\n",
    "    if target in cols_to_scale:\n",
    "        target_idx = cols_to_scale.index(target)\n",
    "        dummy = np.zeros((len(final_predictions), len(cols_to_scale)))\n",
    "        dummy[:, target_idx] = final_predictions[:, idx_col]\n",
    "        inv_transformed = scaler.inverse_transform(dummy)\n",
    "        final_predictions_original[:, idx_col] = inv_transformed[:, target_idx]\n",
    "\n",
    "# Create forecast dataframe with original scale values\n",
    "forecast_df = pd.DataFrame(final_predictions_original, columns=TARGET_VARIABLES)\n",
    "\n",
    "# Create forecast dataframe\n",
    "forecast_df['Date'] = test_df_forecast['Date'].values\n",
    "\n",
    "print(\"\\n✓ Forecast complete!\")\n",
    "print(\"\\nForecast Summary (Sept - Dec 2025):\")\n",
    "display(forecast_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "source": "# DIAGNOSTIC: Check if forecast values are reasonable\nprint(\"\\n\" + \"=\"*80)\nprint(\"FORECAST DIAGNOSTICS\")\nprint(\"=\"*80)\n\nprint(f\"\\nForecast Statistics:\")\nprint(f\"  Revenue - Min: AED {forecast_df['Revenue'].min():,.2f}, Max: AED {forecast_df['Revenue'].max():,.2f}\")\nprint(f\"  RevPar - Min: AED {forecast_df['RevPar'].min():.2f}, Max: AED {forecast_df['RevPar'].max():.2f}\")\nprint(f\"  ADR - Min: AED {forecast_df['ADR'].min():.2f}, Max: AED {forecast_df['ADR'].max():.2f}\")\nprint(f\"  Occupancy - Min: {forecast_df['Occupancy_Pct'].min():.2f}%, Max: {forecast_df['Occupancy_Pct'].max():.2f}%\")\n\nprint(f\"\\nHistorical Comparison (2024 Sept-Dec for reference):\")\nhist_comp = df_clean[(df_clean['Date'] >= '2024-09-01') & (df_clean['Date'] <= '2024-12-31')]\nif len(hist_comp) > 0:\n    print(f\"  2024 Sept-Dec Revenue: AED {hist_comp['Revenue'].sum():,.2f}\")\n    print(f\"  2025 Forecast: AED {forecast_df['Revenue'].sum():,.2f}\")\n    diff_pct = ((forecast_df['Revenue'].sum() / hist_comp['Revenue'].sum()) - 1) * 100\n    print(f\"  Difference: {diff_pct:+.1f}%\")\nelse:\n    print(\"  No 2024 Sept-Dec data available for comparison\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Final Visualization and Total Revenue Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOTAL REVENUE PROJECTION (SEPT - DEC 2025)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate totals\n",
    "total_revenue = forecast_df['Revenue'].sum()\n",
    "avg_revpar = forecast_df['RevPar'].mean()\n",
    "avg_adr = forecast_df['ADR'].mean()\n",
    "avg_occupancy = forecast_df['Occupancy_Pct'].mean()\n",
    "\n",
    "print(f\"\\nProjected Totals (September 1 - December 31, 2025):\")\n",
    "print(f\"  Total Revenue: AED {total_revenue:,.2f}\")\n",
    "print(f\"  Average RevPar: AED {avg_revpar:.2f}\")\n",
    "print(f\"  Average ADR: AED {avg_adr:.2f}\")\n",
    "print(f\"  Average Occupancy: {avg_occupancy:.2f}%\")\n",
    "\n",
    "# Monthly breakdown\n",
    "forecast_df['Month'] = pd.to_datetime(forecast_df['Date']).dt.month\n",
    "monthly_summary = forecast_df.groupby('Month').agg({\n",
    "    'Revenue': 'sum',\n",
    "    'RevPar': 'mean',\n",
    "    'ADR': 'mean',\n",
    "    'Occupancy_Pct': 'mean'\n",
    "})\n",
    "\n",
    "print(\"\\nMonthly Breakdown:\")\n",
    "monthly_summary.index = ['September', 'October', 'November', 'December']\n",
    "display(monthly_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Full Year 2025 Summary (Actual + Forecasted)\n",
    "\n",
    "Combine actual data (Jan-Aug) with forecast (Sept-Dec) for complete year view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"FULL YEAR 2025 SUMMARY (ACTUAL + FORECASTED)\")\nprint(\"=\"*80)\n\n# FIXED: Get actual data for Jan-Aug 2025 and INVERSE TRANSFORM\nactual_2025_scaled = ml_ready_data[(ml_ready_data['Date'] >= '2025-01-01') &\n                                    (ml_ready_data['Date'] <= '2025-08-29')].copy()\n\n# The data in ml_ready_data is SCALED, so we need to inverse transform it\n# Create a copy for inverse transformation\nactual_2025_original = actual_2025_scaled.copy()\n\n# Inverse transform each target variable\nfor target in TARGET_VARIABLES:\n    if target in cols_to_scale:\n        target_idx = cols_to_scale.index(target)\n        \n        # Get scaled values\n        scaled_values = actual_2025_scaled[target].values\n        \n        # Create dummy array for inverse transform\n        dummy = np.zeros((len(scaled_values), len(cols_to_scale)))\n        dummy[:, target_idx] = scaled_values\n        \n        # Inverse transform\n        inv_transformed = scaler.inverse_transform(dummy)\n        actual_2025_original[target] = inv_transformed[:, target_idx]\n\n# Now calculate metrics from ORIGINAL scale data\nactual_revenue_ytd = actual_2025_original['Revenue'].sum()\nactual_avg_revpar = actual_2025_original['RevPar'].mean()\nactual_avg_adr = actual_2025_original['ADR'].mean()\nactual_avg_occ = actual_2025_original['Occupancy_Pct'].mean()\n\n# Forecast totals (Sept-Dec)\nforecast_revenue = forecast_df['Revenue'].sum()\nforecast_avg_revpar = forecast_df['RevPar'].mean()\nforecast_avg_adr = forecast_df['ADR'].mean()\nforecast_avg_occ = forecast_df['Occupancy_Pct'].mean()\n\n# Full year totals\nfull_year_revenue = actual_revenue_ytd + forecast_revenue\nfull_year_avg_revpar = (actual_avg_revpar * len(actual_2025_original) + forecast_avg_revpar * len(forecast_df)) / (len(actual_2025_original) + len(forecast_df))\nfull_year_avg_adr = (actual_avg_adr * len(actual_2025_original) + forecast_avg_adr * len(forecast_df)) / (len(actual_2025_original) + len(forecast_df))\nfull_year_avg_occ = (actual_avg_occ * len(actual_2025_original) + forecast_avg_occ * len(forecast_df)) / (len(actual_2025_original) + len(forecast_df))\n\nprint(f\"\\n2025 Year-to-Date (Jan 1 - Aug 29): ACTUAL\")\nprint(f\"  Days: {len(actual_2025_original)}\")\nprint(f\"  Total Revenue: AED {actual_revenue_ytd:,.2f}\")\nprint(f\"  Average RevPar: AED {actual_avg_revpar:,.2f}\")\nprint(f\"  Average ADR: AED {actual_avg_adr:,.2f}\")\nprint(f\"  Average Occupancy: {actual_avg_occ:.2f}%\")\n\nprint(f\"\\n2025 Forecast (Sept 1 - Dec 31): FORECASTED\")\nprint(f\"  Days: {len(forecast_df)}\")\nprint(f\"  Total Revenue: AED {forecast_revenue:,.2f}\")\nprint(f\"  Average RevPar: AED {forecast_avg_revpar:,.2f}\")\nprint(f\"  Average ADR: AED {forecast_avg_adr:,.2f}\")\nprint(f\"  Average Occupancy: {forecast_avg_occ:.2f}%\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FULL YEAR 2025 TOTALS (Jan 1 - Dec 31)\")\nprint(\"=\"*80)\nprint(f\"  Total Days: {len(actual_2025_original) + len(forecast_df)}\")\nprint(f\"  Total Revenue: AED {full_year_revenue:,.2f}\")\nprint(f\"  Average RevPar: AED {full_year_avg_revpar:,.2f}\")\nprint(f\"  Average ADR: AED {full_year_avg_adr:,.2f}\")\nprint(f\"  Average Occupancy: {full_year_avg_occ:.2f}%\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"BREAKDOWN BY PERIOD\")\nprint(\"=\"*80)\n\n# Create comparison table\nsummary_table = pd.DataFrame({\n    'Period': ['Jan-Aug (Actual)', 'Sept-Dec (Forecast)', 'Full Year 2025'],\n    'Days': [len(actual_2025_original), len(forecast_df), len(actual_2025_original) + len(forecast_df)],\n    'Total Revenue (AED)': [\n        f'{actual_revenue_ytd:,.2f}',\n        f'{forecast_revenue:,.2f}',\n        f'{full_year_revenue:,.2f}'\n    ],\n    'Avg RevPar (AED)': [\n        f'{actual_avg_revpar:,.2f}',\n        f'{forecast_avg_revpar:,.2f}',\n        f'{full_year_avg_revpar:,.2f}'\n    ],\n    'Avg ADR (AED)': [\n        f'{actual_avg_adr:,.2f}',\n        f'{forecast_avg_adr:,.2f}',\n        f'{full_year_avg_adr:,.2f}'\n    ],\n    'Avg Occupancy (%)': [\n        f'{actual_avg_occ:.2f}',\n        f'{forecast_avg_occ:.2f}',\n        f'{full_year_avg_occ:.2f}'\n    ]\n})\n\ndisplay(summary_table)\n\n# Monthly breakdown for full year\nprint(\"\\n\" + \"=\"*80)\nprint(\"MONTHLY BREAKDOWN - 2025\")\nprint(\"=\"*80)\n\n# Get monthly data for actual\nactual_2025_original['Month_Num'] = pd.to_datetime(actual_2025_original['Date']).dt.month\nactual_monthly = actual_2025_original.groupby('Month_Num').agg({\n    'Revenue': 'sum',\n    'RevPar': 'mean',\n    'ADR': 'mean',\n    'Occupancy_Pct': 'mean'\n})\n\n# Get monthly data for forecast\nforecast_df['Month_Num'] = pd.to_datetime(forecast_df['Date']).dt.month\nforecast_monthly = forecast_df.groupby('Month_Num').agg({\n    'Revenue': 'sum',\n    'RevPar': 'mean',\n    'ADR': 'mean',\n    'Occupancy_Pct': 'mean'\n})\n\n# Combine\nimport calendar\nmonthly_full = pd.concat([actual_monthly, forecast_monthly]).groupby(level=0).first()\nmonthly_full.index = [calendar.month_name[i] for i in monthly_full.index]\n\n# Format for display\nmonthly_display = monthly_full.copy()\nmonthly_display['Type'] = ['Actual']*8 + ['Forecast']*4\nmonthly_display = monthly_display[['Type', 'Revenue', 'RevPar', 'ADR', 'Occupancy_Pct']]\nmonthly_display.columns = ['Type', 'Revenue (AED)', 'RevPar (AED)', 'ADR (AED)', 'Occupancy (%)']\n\ndisplay(monthly_display)\n\nprint(f\"\\n{'='*80}\")\nprint(f\"2025 ANNUAL REVENUE: AED {full_year_revenue:,.2f}\")\nprint(f\"{'='*80}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Historical + Forecast\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Combine historical and forecast data for plotting\n",
    "historical_data = ml_ready_data[ml_ready_data['Date'] <= VALIDATION_END].copy()\n",
    "\n",
    "for idx, var in enumerate(TARGET_VARIABLES):\n",
    "    # Plot historical data\n",
    "    axes[idx].plot(historical_data['Date'], historical_data[var], \n",
    "                   linewidth=1.5, color='blue', label='Historical (Actual)', alpha=0.7)\n",
    "    \n",
    "    # Plot forecast\n",
    "    axes[idx].plot(forecast_df['Date'], forecast_df[var], \n",
    "                   linewidth=2, color='red', label='Forecast (Sept-Dec 2025)', marker='o')\n",
    "    \n",
    "    # Add vertical lines\n",
    "    axes[idx].axvline(x=pd.to_datetime(TRAIN_END), color='green', \n",
    "                      linestyle='--', alpha=0.5, label='Train End')\n",
    "    axes[idx].axvline(x=pd.to_datetime(VALIDATION_END), color='orange', \n",
    "                      linestyle='--', alpha=0.5, label='Validation End')\n",
    "    \n",
    "    axes[idx].set_title(f'{var} - Historical vs Forecast', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date', fontsize=11)\n",
    "    axes[idx].set_ylabel(var, fontsize=11)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Model Diagnostics: Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS (XGBOOST)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get feature importance for RevPar model (first target)\n",
    "revpar_model = final_xgb.estimators_[0]  # First estimator is for RevPar\n",
    "feature_importance = revpar_model.feature_importances_\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "top_n = 20\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(top_n), importance_df['Importance'].head(top_n), color='steelblue')\n",
    "plt.yticks(range(top_n), importance_df['Feature'].head(top_n))\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title(f'Top {top_n} Feature Importance (RevPar Prediction)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "display(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Residual Analysis (Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals on validation set\n",
    "residuals = y_val.values - xgb_val_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, target in enumerate(TARGET_VARIABLES):\n",
    "    axes[idx].scatter(val_df_clean['Date'].values, residuals[:, idx], \n",
    "                     alpha=0.6, color='purple')\n",
    "    axes[idx].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[idx].set_title(f'{target} - Residuals vs Time (Validation)', \n",
    "                       fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date', fontsize=11)\n",
    "    axes[idx].set_ylabel('Residuals', fontsize=11)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Export Final Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export forecast to CSV\n",
    "forecast_output = 'hotel_revenue_forecast_sept_dec_2025.csv'\n",
    "forecast_df.to_csv(forecast_output, index=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FORECAST EXPORT COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ Forecast saved to: {forecast_output}\")\n",
    "\n",
    "# Download\n",
    "files.download(forecast_output)\n",
    "print(\"\\n✓ File downloaded!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJECT COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFinal 2025 Revenue Projection (Sept-Dec): ${total_revenue:,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}